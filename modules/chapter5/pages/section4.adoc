= Resource Capacity Calculation

== CPU capacity calculation

[source,subs="+quotes"]
----
Formula

(((physical_cpu_cores - odf_requirements - control_plane_requirements) * node_count * overcommitment_ratio) * (1 -ha_reserve_percent)) * (1 - spare_capacity_percent)
----

* physical_cpu_cores = the number of physical cores available on the node.
* odf_requirements = the amount of resources reserved for ODF. A value of 32 cores was used for the example architectures.
* control_plane_requirements = the amount of CPU reserved for the control plane workload. A value of 4 cores was used for the example architectures.
* node_count = the number of nodes with this geometry. For small, all nodes were equal. For medium, the nodes are mixed-purpose, so the previous steps would need to be repeated for each node type, taking into account the appropriate node type.
* overcommitment_ratio = the amount of CPU overcommitment. A ratio of 4:1 was used for this document.
* spare_capacity = the amount of capacity reserved for spare/burst. A value of 10% was used for this document.
* ha_reserve_percent = the amount of capacity reserved for recovering workload lost in the event of node failure. For the small example, a value of 25% was used, allowing for one node to fail. For the medium example, a value of 20% was used, allowing for two nodes to fail.

== Memory capacity calculation

[source,subs="+quotes"]
----
Formula

((total_node_memory - odf_requirements - control_plane_requirements) * soft_eviction_threshold_percent * node_count) * (1 - ha_reserve_percent)
----

* total_node_memory = the total physical memory installed on the node.
* odf_requirements = the amount of memory assigned to ODF. A value of 72GiB was used for the example architectures in this document.
* control_plane_requirements = the amount of memory reserved for the control plane functions. A value of 24GiB was used for the example architectures.
* soft_eviction_threshold_percent = the value at which soft eviction is triggered to rebalance resource utilization on the node. Unless all nodes in the cluster exceed this value, itâ€™s expected that the node will be below this utilization. A value of 90% was used for this document.
* node_count = the number of nodes with this geometry. For small, all nodes were equal. For medium, the nodes are mixed-purpose, so the previous steps would need to be repeated for each node type, taking into account the appropriate node type.
* ha_reserve_percent = the amount of capacity reserved for recovering workload lost in the event of node failure. For the small example, a value of 25% was used, allowing for one node to fail. For the medium example, a value of 20% was used, allowing for two nodes to fail.

== ODF storage capacity calculation

[source,subs="+quotes"]
----
Formula

(((disk_size * disk_count) * node_count) / replica_count) * (1 - utilization_percent)
----

* disk_size = the size of the disk(s) used. 4TB and 8TB disks were used in the example architectures.
* disk_count = the number of disks of disk_size in the node.
* node_count = the number of nodes with this geometry. For small, all nodes were equal. For medium, the nodes are mixed-purpose, so the previous steps would need to be repeated for each node type taking into account the appropriate node type.
* replica_count = the number of copies ODF stores of the data for protection/resiliency. A value of 3 was used for this document.
* utilization_percent = the desired threshold of capacity used in the ODF instance. A value of 65% was used for this document.
